{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_to_embedding.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "hmZDpK4gDfvJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text to Word Embedding\n",
        "\n",
        "Here we use [Tencent AI Lab Embedding](https://ai.tencent.com/ailab/nlp/embedding.html) (8824330 words, 200 dimensional) to get word level and char level features."
      ]
    },
    {
      "metadata": {
        "id": "Rzvf5mN0sKOa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1 Download & Decompress"
      ]
    },
    {
      "metadata": {
        "id": "2p4eSNf3gwuG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -c https://ai.tencent.com/ailab/nlp/data/Tencent_AILab_ChineseEmbedding.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ec69fLVghXOu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tar -xzvf Tencent_AILab_ChineseEmbedding.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rl_O50nOhZTO",
        "colab_type": "code",
        "outputId": "bbb12be7-087a-4b66-df43-a9dac016106e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lh"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 22G\n",
            "-rw-r--r-- 1 root root 1.8K Oct 19 10:41 README.txt\n",
            "-rw-r--r-- 1 root root 6.4G Oct 19 11:29 Tencent_AILab_ChineseEmbedding.tar.gz\n",
            "-rw-r--r-- 1 root root  16G Oct 19 10:50 Tencent_AILab_ChineseEmbedding.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IQYDw9jUhbzK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!head Tencent_AILab_ChineseEmbedding.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QofeLo6nGint",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2 Extract embeddings needed\n",
        "\n",
        "To save space and memory, we only extract words and chars that appear in the dataset.\n",
        "\n",
        "You may only apply this method when we already have the text to be predicted."
      ]
    },
    {
      "metadata": {
        "id": "1sFF8bTpjqVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "!pip install jieba tqdm > /dev/null\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import jieba\n",
        "from tqdm import tqdm\n",
        "\n",
        "jieba.setLogLevel(20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccZopX0UeLaj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.1 Read text and cut for words and chars"
      ]
    },
    {
      "metadata": {
        "id": "8zdJVPf11Edi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/gdrive/My Drive/Colab Notebooks/labelled.txt'\n",
        "labelled = pd.read_csv(path, sep='\\t', header=None)\n",
        "y = labelled[0].tolist()\n",
        "contents = labelled[1].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Hcx-J_wDWK9d",
        "colab_type": "code",
        "outputId": "e1cc3347-348e-4680-b5ed-3c20e0432df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "contents_word, contents_char, contents_woch = [], [], []\n",
        "wordset, charset = set(), set()\n",
        "for content in tqdm(texts):\n",
        "    words = list(jieba.cut_for_search(content))\n",
        "    chars = list(content)\n",
        "    contents_word.append(words)\n",
        "    contents_char.append(chars)\n",
        "    contents_woch.append(words + chars)\n",
        "    wordset.update(words)\n",
        "    charset.update(chars)\n",
        "wochset = wordset.union(charset)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 754843/754843 [03:24<00:00, 3686.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "td2O5-nv6O0o",
        "colab_type": "code",
        "outputId": "9b6195fc-b38c-44bf-8267-117bc5ed1816",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "[len(s) for s in [wordset, charset, wochset]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[385237, 8760, 386813]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "TUEsv79veRLE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2 Select appeared words and chars"
      ]
    },
    {
      "metadata": {
        "id": "_jjtmMnXiQfK",
        "colab_type": "code",
        "outputId": "7453e280-bd19-4646-c157-05b67f9e83aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_index, embedding_matrix_word = {}, []\n",
        "char_index, embedding_matrix_char = {}, []\n",
        "woch_index, embedding_matrix_woch = {}, []\n",
        "with open('Tencent_AILab_ChineseEmbedding.txt') as f:\n",
        "    next(f)\n",
        "    i = j = k = 0\n",
        "    for line in tqdm(f, total=8824330):\n",
        "        e = line[:-1].split(' ')\n",
        "        w, v = e[0], np.array(e[1:], dtype=float)\n",
        "        if w in wordset:\n",
        "            word_index[w] = i\n",
        "            i += 1\n",
        "            embedding_matrix_word.append(v)\n",
        "        if w in charset:\n",
        "            char_index[w] = j\n",
        "            j += 1\n",
        "            embedding_matrix_char.append(v)\n",
        "        if w in wochset:\n",
        "            woch_index[w] = k\n",
        "            k += 1\n",
        "            embedding_matrix_woch.append(v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 8824330/8824330 [12:19<00:00, 11932.58it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wuJ03AIvpsTe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embeddings_word = [word_index, np.array(embedding_matrix_word)]\n",
        "embeddings_char = [char_index, np.array(embedding_matrix_char)]\n",
        "embeddings_woch = [woch_index, np.array(embedding_matrix_woch)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IkhRHYbT9gV9",
        "colab_type": "code",
        "outputId": "f9ff4a5b-42e2-48a1-a0f2-2bdb79aeef21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "[len(i) for i in [word_index, char_index, woch_index]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[273139, 8656, 274713]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "9v_YS_Ub9EoM",
        "colab_type": "code",
        "outputId": "34b63f2f-157e-492a-a67c-c73a86c3f0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "[e[1].shape for e in [embeddings_word, embeddings_char, embeddings_woch]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(273139, 200), (8656, 200), (274713, 200)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "-UVWe1pDTXK1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3 Text to embedding indexes"
      ]
    },
    {
      "metadata": {
        "id": "NKBw-1aTx2jR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Generate embedding for out of vocabulary words\n",
        "\n",
        "Similar  to [Kim (2014)](https://www.aclweb.org/anthology/D14-1181)."
      ]
    },
    {
      "metadata": {
        "id": "4GBoAT9YbWHg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "std = np.std(embeddings_woch[1], axis=0)\n",
        "unk = np.random.uniform(-1, 1, embeddings_woch[1].shape[1]) * std\n",
        "unk = unk.reshape(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uD8u6i4fqKbL",
        "colab_type": "code",
        "outputId": "0154a58f-6335-4c7f-a5b1-29b32e851f8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "['<UNK>' in e[0].keys() \n",
        " for e in [embeddings_word, embeddings_char, embeddings_woch]]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, False, False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "wv4ocNKmo3-d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Text to indexes"
      ]
    },
    {
      "metadata": {
        "id": "T4kbTBxtT0OG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def text_to_indexes(embeddings, contents):\n",
        "    index, e_mat = embeddings\n",
        "    # Add unknown word token to embedding matrix.\n",
        "    index['<UNK>'] = len(index.keys())\n",
        "    e_mat = np.concatenate([e_mat, unk], axis=0)\n",
        "    indexes = [[index[element] if element in index.keys() else index['<UNK>']\n",
        "                for element in content] for content in tqdm(contents) ]\n",
        "    return (index, e_mat), indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Ag8PCp-aMrn",
        "colab_type": "code",
        "outputId": "b0fd5d4b-7bad-4c7c-a69f-1e45872b2398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "embeddings_word, X_word = text_to_indexes(embeddings_word, contents_word)\n",
        "embeddings_char, X_char = text_to_indexes(embeddings_char, contents_char)\n",
        "embeddings_woch, X_woch = text_to_indexes(embeddings_woch, contents_woch)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 754843/754843 [00:10<00:00, 71807.84it/s] \n",
            "100%|██████████| 754843/754843 [00:10<00:00, 72703.26it/s] \n",
            "100%|██████████| 754843/754843 [00:16<00:00, 45877.72it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1kasqKbptLGo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4 Pickle and save"
      ]
    },
    {
      "metadata": {
        "id": "0HSu1l8e1l_i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pickle.dump(embeddings_word, open('embeddings_word.p', 'wb'))\n",
        "pickle.dump(embeddings_char, open('embeddings_char.p', 'wb'))\n",
        "pickle.dump(embeddings_woch, open('embeddings_woch.p', 'wb'))\n",
        "pickle.dump(X_word, open('X_word.p', 'wb'))\n",
        "pickle.dump(X_char, open('X_char.p', 'wb'))\n",
        "pickle.dump(X_woch, open('X_woch.p', 'wb'))\n",
        "pickle.dump(y, open('y.p', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "thRUmk9NxD6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm c*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPgLISHM1p_r",
        "colab_type": "code",
        "outputId": "c01739fc-e44c-441f-a7ed-f50830b359f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -lh *.p"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw------- 1 root root  14M Dec  1 07:55 embeddings_char.p\n",
            "-rw------- 1 root root 425M Dec  1 07:55 embeddings_woch.p\n",
            "-rw------- 1 root root 423M Dec  1 07:55 embeddings_word.p\n",
            "-rw-r--r-- 1 root root  58M Dec  1 07:55 X_char.p\n",
            "-rw-r--r-- 1 root root  99M Dec  1 07:55 X_woch.p\n",
            "-rw-r--r-- 1 root root  42M Dec  1 07:55 X_word.p\n",
            "-rw------- 1 root root 1.5M Dec  1 07:55 y.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IEgv2VfhpIQB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!cp *.p /gdrive/My\\ Drive/Colab\\ Notebooks"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}